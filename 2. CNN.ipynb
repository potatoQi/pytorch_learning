{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是 Tiny Imagenet 数据集的预处理\n",
    "'''\n",
    "Tiny Imagenet 有 200 个类。 每个类有 500 张训练图像、50 张验证图像和 50 张测试图像。\n",
    "所以一共 100000 张训练图像、10000 张验证图像和 10000 张测试图像。\n",
    "train 为训练集, val 为验证集。这俩数据集有标签。\n",
    "这个数据集大部分是 RGB, 但是也有少部分是灰度图。\n",
    "图片大小都是 64x64。\n",
    "'''\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "\n",
    "class TinyImagenet(Dataset):\n",
    "    mapping = {}    # 类的静态变量, 用来后面验证正确性用的\n",
    "\n",
    "    def __init__(self, root, type):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.type = type\n",
    "        \n",
    "        if not os.path.exists(root):\n",
    "            raise ValueError(\"dataset path not right!\")\n",
    "        if type not in ['train', 'val']:\n",
    "            raise ValueError(\"dataset type not right!\")\n",
    "        \n",
    "        self.annotations_file = self.get_annotations_file(type)\n",
    "\n",
    "    def get_annotations_file(self, type):\n",
    "        df = pd.DataFrame(columns=['img_name', 'label'])\n",
    "        rows = []\n",
    "        mapping = {}\n",
    "        with open(os.path.join(self.root, 'wnids.txt'), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip() for line in lines]\n",
    "            for idx, line in enumerate(lines):\n",
    "                mapping[line] = idx\n",
    "                TinyImagenet.mapping[line] = idx\n",
    "\n",
    "        if type == 'train':\n",
    "            '''\n",
    "            去遍历 train 下面的每个子文件夹\n",
    "                对于每个子文件夹, 通过文件夹名 mapping 找到对应的 label\n",
    "                对于每个子文件夹, 进入其下的 txt, 把第一列读出来, 作为 img_names, 然后把所有 pairs 存到 rows 里\n",
    "            '''\n",
    "            path_train = os.path.join(self.root, 'train')\n",
    "            for entry in os.listdir(path_train):\n",
    "                label = mapping[entry]\n",
    "                with open(os.path.join(path_train, entry, entry + '_boxes.txt'), 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    for line in lines:\n",
    "                        img_name = line.split('\\t')[0]\n",
    "                        rows.append({'img_name': img_name, 'label': label})\n",
    "\n",
    "        elif type == 'val':\n",
    "            '''\n",
    "            进入 val 下的 txt, 把前两列读出来, 然后用 mapping 换为 label 即可\n",
    "            '''\n",
    "            with open(os.path.join(self.root, 'val', 'val_annotations.txt'), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    img_name, id, _, _, _, _ = line.split('\\t')\n",
    "                    label = mapping[id]\n",
    "                    rows.append({'img_name': img_name, 'label': label})\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(rows)], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.annotations_file.iloc[idx, 1]\n",
    "        img_name = self.annotations_file.iloc[idx, 0]\n",
    "\n",
    "        if self.type == 'train':\n",
    "            catagory = img_name.split('_')[0]\n",
    "            img = read_image(os.path.join(self.root, 'train', catagory, 'images', img_name))\n",
    "        elif self.type == 'val':\n",
    "            img = read_image(os.path.join(self.root, 'val', 'images', img_name))\n",
    "\n",
    "        if img.shape[0] == 1: # 有可能出现灰度图, 要转为 RGB\n",
    "            img = img.repeat(3, 1, 1) # tensor.repeat(x, y, z) 表示下标为 0 的维度重复 x 次, 依次类推\n",
    "        img = img.to(torch.float32) / 255.0 # read_image 读出来的是 torch.uint8, 要转为 [0, 1]\n",
    "\n",
    "        return img, label\n",
    "        \n",
    "# 验证下自定义数据集声明是否正确 (检查图片与标签的对应关系)\n",
    "train_TinyImagenetData = TinyImagenet(root=\"./data/tiny-imagenet-200\", type=\"train\")\n",
    "test_TinyImagenetData = TinyImagenet(root=\"./data/tiny-imagenet-200\", type=\"val\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_TinyImagenetDataloader = DataLoader(train_TinyImagenetData, batch_size=8, shuffle=True)\n",
    "test_TinyImagenetDataloader = DataLoader(test_TinyImagenetData, batch_size=8, shuffle=True)\n",
    "\n",
    "mapping = {}\n",
    "with open('./data/tiny-imagenet-200/words.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        id, desc = line.split('\\t')\n",
    "        mapping[TinyImagenet.mapping.get(id)] = desc.strip().split(',')[0]  # 太长了, 只取第一个\n",
    "\n",
    "a = next(iter(train_TinyImagenetDataloader))\n",
    "b = next(iter(test_TinyImagenetDataloader))\n",
    "# print(a[0][x].shape, a[1][x]) # x 为 0 到 7\n",
    "# print(b[0][x].shape, b[1][x]) # x 为 0 到 7\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "rows, cols = 4, 4\n",
    "for i, j in zip(range(1, 8 + 1), range(0, 8)):\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.title(mapping[a[1][j].item()])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(a[0][j].permute(1, 2, 0))\n",
    "for i, j in zip(range(9, 16 + 1), range(0, 8)):\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.title(mapping[b[1][j].item()])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(b[0][j].permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "# 总结: 主要还是要把 self.annotations_file 弄出来, 这玩意弄出来都好写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务:\n",
    "# 1. 读入 FashionMNIST, CIFAR10, Tiny Imagenet(来自CS231n课程项目) 数据集\n",
    "# 2. 构建 CNN 网络, 写 train/eval loop, 带调试信息\n",
    "# 3. 训练, 保存, 加载\n",
    "\n",
    "# 数据集导入\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "op_dataset = 2  # 0: FashionMNIST, 1: CIFAR10, 2: TinyImagenet\n",
    "op_model = 0    # 0: LetNet\n",
    "\n",
    "if op_dataset == 0:\n",
    "    catagoty_num = 10\n",
    "    train_data = datasets.FashionMNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "elif op_dataset == 1:\n",
    "    catagoty_num = 10\n",
    "    train_data = datasets.CIFAR10(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "    test_data = datasets.CIFAR10(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "elif op_dataset == 2:\n",
    "    catagoty_num = 200\n",
    "    train_data = TinyImagenet('./data/tiny-imagenet-200', 'train')\n",
    "    test_data = TinyImagenet('./data/tiny-imagenet-200', 'val')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size= batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "print('训练集和测试集的样本数量')\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LetNet\n",
    "from torch import nn\n",
    "\n",
    "sample = train_data[0][0]\n",
    "\n",
    "class LetNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=sample.shape[0], out_channels=6, kernel_size=5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(self.get_flatten_dim(), 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, catagoty_num)\n",
    "\n",
    "    def get_flatten_dim(self):\n",
    "        with torch.no_grad():\n",
    "            x = self.pool(self.conv1(sample.unsqueeze(0)))  # 增加 batch 维度\n",
    "            x = self.pool(self.conv2(x))\n",
    "            return x.numel()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/eval\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if op_model == 0:\n",
    "    model = LetNet().to(device)\n",
    "    model_name = 'LetNet'\n",
    "    \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train_loop(model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    samples_size = len(dataloader.dataset)\n",
    "    batches_size = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits_pred = model(X)\n",
    "        loss = loss_fn(logits_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0 or batch == batches_size - 1:\n",
    "            print(f'loss:{loss:>7.2f} | {batch * batch_size + len(y)}/{samples_size}')\n",
    "\n",
    "def test_loop(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    samples_size = len(dataloader.dataset)\n",
    "    batches_size = len(dataloader)\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits_pred = model(X)\n",
    "        loss_sum += loss_fn(logits_pred, y)\n",
    "        acc_sum += (logits_pred.argmax(dim=1) == y).sum()\n",
    "    print(f'loss:{(loss_sum/batches_size):>7.2f} | acc:{(acc_sum/samples_size*100):>7.2f}%')\n",
    "\n",
    "epochs = 10\n",
    "for t in range(1, epochs + 1):\n",
    "    print(f'Epoch {t} -------------------------')\n",
    "    train_loop(model, train_dataloader, loss_fn, optimizer)\n",
    "    test_loop(model, test_dataloader, loss_fn)\n",
    "    print()\n",
    "\n",
    "# 保存/加载模型\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "torch.save(model.state_dict(), os.path.join('./model', model_name + '.pth'))\n",
    "\n",
    "model_new = LetNet().to(device)\n",
    "model_new.load_state_dict(torch.load(os.path.join('./model', model_name + '.pth')))\n",
    "model_new.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model_new(sample.unsqueeze(0).to(device)).argmax()\n",
    "print(y_pred, train_data[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
